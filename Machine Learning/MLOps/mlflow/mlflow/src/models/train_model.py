import math
import mlflow
import argparse
import pandas as pd
import xgboost
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from mlflow.models.signature import infer_signature

# NOTE: In order to be shown on MLFlow, the MLRuns generated by the
# mlflow ui command must be in the same mlruns context as of this training model


def parse_args():
    parser = argparse.ArgumentParser(description='House Prices ML')
    parser.add_argument(
        '--learning-rate',
        type=float,
        default=0.3,
        help='learning rate to update the size of each boosting step'
    )
    parser.add_argument(
        '--max-depth',
        type=int,
        default=6,
        help='max tree depth'
    )
    return parser.parse_args()


def main():
    args = parse_args()

    xgb_params = {
        'learning_rate': args.learning_rate,
        'max_depth': args.max_depth,
        'seed': 42
    }

    # df = pd.read_csv('../../data/processed/data.csv')
    df = pd.read_csv('mlflow/data/processed/data.csv')
    df.head()

    mlflow.set_tracking_uri('http://127.0.0.1:5000')
    mlflow.set_experiment('house-prices-scripts')

    with mlflow.start_run():
        # Sets autolog for xgboost model
        mlflow.xgboost.autolog()

        X = df.drop('price', axis=1)
        y = df['price'].copy()

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42)

        dtrain = xgboost.DMatrix(X_train, label=y_train)
        dtest = xgboost.DMatrix(X_test, label=y_test)

        xgb = xgboost.train(xgb_params, dtrain, evals=[(dtrain, 'train')])
        xgb_predicted = xgb.predict(dtest)

        mse = mean_squared_error(y_test, xgb_predicted)
        rmse = math.sqrt(mse)
        r2 = r2_score(y_test, xgb_predicted)

        mlflow.log_metric('mse', mse)
        mlflow.log_metric('rmse', rmse)
        mlflow.log_metric('r2', r2)


if __name__ == '__main__':
    main()
